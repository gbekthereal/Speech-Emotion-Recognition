{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport pathlib\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\nimport torchaudio\nimport librosa.display\nimport IPython.display as ipd\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n############################################################################################\n##########\n# input data\npaths = pathlib.Path(\"/kaggle/input/dataset/Acted Emotional Speech Dynamic Database\").glob(\"**/*.wav\")\npaths_list = list(paths)\n# extract dataset\ndata = []\nfor path in tqdm(paths_list):\n name = str(path).split('/')[-1].split('.')[0]\n label = str(path).split('/')[-2]\n try:\n s = torchaudio.load(path)\n data.append({\"name\": name, \"speech\": path, \"label\": label})\n except Exception as e:\n pass\ndf = pd.DataFrame(data)\ndf = df.reset_index(drop=True)\n############################################################################################\n##########\n# data analysis\nfor category in df[\"label\"].unique():\n temp = (df['label'] == category).sum()\n print(\"label \", category, \" has in total \", temp, \" features\")\n############################################################################################\n##########\n# display the waveform of the audio file\ndef waveplot(data, sr, emotion):\n plt.figure(figsize=(10,4))\n plt.title(emotion, size=20)\n librosa.display.waveshow(data, sr=sampling_rate)\n plt.show()\nemotion = 'fear'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\ndisplay(ipd.Audio(path))\nprint(\"\\n\\n\")\nemotion = 'sadness'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\ndisplay(ipd.Audio(path))\nprint(\"\\n\\n\")\nemotion = 'disgust'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\ndisplay(ipd.Audio(path))\nprint(\"\\n\\n\")\nemotion = 'happiness'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\ndisplay(ipd.Audio(path))\nprint(\"\\n\\n\")\nemotion = 'anger'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\ndisplay(ipd.Audio(path))\n############################################################################################\n##########\n# Feature Extraction\ndef extract_mfcc(filename):\n y, sr = librosa.load(filename, duration=3, offset=0.5)\n mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n return mfcc\nX_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\nX = np.array([x for x in X_mfcc])\nX = np.expand_dims(X, -1)\n# anger: 0 0 0 0 1\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])\ny = y.toarray()\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n############################################################################################\n##########\n# neural network\nmodel = Sequential([\n LSTM(256, return_sequences=False, input_shape=(40,1)),\n Dropout(0.2),\n Dense(128, activation='relu'),\n Dropout(0.2),\n Dense(5, activation='softmax')\n])\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(x_train, y_train, validation_split=0.2, epochs=50, batch_size=64)\nscores = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))\n############################################################################################\n##########\n# Plot the results\nepochs = list(range(50))\nacc, val_acc = history.history['accuracy'], history.history['val_accuracy']\nplt.plot(epochs, acc, label='train accuracy')\nplt.plot(epochs, val_acc, label='val accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()\nloss, val_loss = history.history['loss'], history.history['val_loss']\nplt.plot(epochs, loss, label='train loss')\nplt.plot(epochs, val_loss, label='val loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n############################################################################################\n##########\n# actual results\ny_pred = model.predict(x_test)\ny_pred = enc.inverse_transform(y_pred)\ny_test = enc.inverse_transform(y_test)\npred_test = model.predict(x_test)\ndf = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf['Predicted Labels'] = y_pred.flatten()\ndf['Actual Labels'] = y_test.flatten()\nprint(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}