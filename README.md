Speech Emotion Recognition (SER) is the process of extracting emotional linguistic information from speech.
The performance of such applications depends much of a high-quality speech emotion recognition dataset.

This project was done through the site Kaggle and with the recurrent neural network (RNN) **Long Short-Term Memory)**.
In order to run the code, you have to use the notebook provided by Kaggle and upload the dataset **Acted Emotional Speech Dynamic Database**.

The Acted Emotional Speech Dynamic Database (AESDD) is a publicly available speech emotion recognition dataset, where it contains
pronunciations of active emotional speech in the Greek language.
The database contains five emotions such as anger, disgust, fear, happiness and sadness.

![image](https://github.com/gbekthereal/Speech-Emotion-Recognition/assets/81323878/a5a42117-9b3c-44b1-b12e-2b056ec3c373)

![image](https://github.com/gbekthereal/Speech-Emotion-Recognition/assets/81323878/96efb639-4f89-4090-82f1-44856b961ec7)

![image](https://github.com/gbekthereal/Speech-Emotion-Recognition/assets/81323878/92439cbf-c2d1-4455-bf11-736459a7f081)

![image](https://github.com/gbekthereal/Speech-Emotion-Recognition/assets/81323878/b1e5f610-62c4-4ca6-aaca-d347fd0e54de)

![image](https://github.com/gbekthereal/Speech-Emotion-Recognition/assets/81323878/64b15ca1-3569-40a4-8e1f-d40e4773fd26)
